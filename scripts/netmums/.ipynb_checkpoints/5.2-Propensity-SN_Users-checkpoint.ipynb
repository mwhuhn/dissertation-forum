{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Word Features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LDA\n",
    "from gensim import corpora, models\n",
    "from gensim.models import CoherenceModel, LdaModel, LdaMulticore\n",
    "from gensim.models.callbacks import PerplexityMetric, ConvergenceMetric, CoherenceMetric\n",
    "# Managing data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "# DB connection\n",
    "from scraping import create_connection\n",
    "# Files & I/O\n",
    "import pickle\n",
    "import csv\n",
    "import os\n",
    "from pathlib import Path\n",
    "from io import FileIO\n",
    "# For logging\n",
    "import logging\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "# Random\n",
    "import random\n",
    "# Parallelizing\n",
    "import dask.dataframe as dd\n",
    "from dask.multiprocessing import get"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Path.cwd()\n",
    "path_parent = p.parents[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# database\n",
    "path_db = str(path_parent / \"database\" / \"netmums-merged.db\")\n",
    "path_clean_data = path_parent / \"clean_data\" / \"netmums\"\n",
    "# data to load\n",
    "path_lemma_pkl = str(path_clean_data / \"lemmatized_text_{0}_{1}_{2}.pkl\")\n",
    "path_corpus_pkl = str(path_clean_data / \"corpus_{0}_{1}_{2}.pkl\")\n",
    "path_dictionary_gensim = str(path_clean_data / \"dictionary_{0}_{1}_{2}.gensim\")\n",
    "# model saving\n",
    "path_tune_models = str(path_clean_data / \"lda_tune_{0}_{1}_{2}_{3}_{4}.gensim\")\n",
    "path_ntopic_models = str(path_clean_data / \"lda_ntopics_{0}_{1}_{2}_{3}.gensim\")\n",
    "# path_coherence = str(path_parent / \"clean_data\" / \"coherence_{}.csv\")\n",
    "path_log = str(path_clean_data / \"logging_{0}_{1}_{2}_{3}.log\")\n",
    "path_log_iterations = str(path_clean_data / \"logging_{0}_{1}_{2}_{3}.log\")\n",
    "# dominant topic\n",
    "path_dom_topic = str(path_clean_data / \"dominant_topic_{0}_{1}_{2}_{3}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframes\n",
    "path_topics_pkl = str(path_clean_data / \"daily_topics_sn.pkl\")\n",
    "path_text_pkl = str(path_clean_data / \"daily_clean_text.pkl\")\n",
    "path_topics = str(path_clean_data / \"lda_topics_sn.csv\")\n",
    "# path_days_since_pkl = str(path_clean_data / \"daily_days_since.pkl\")\n",
    "# path_subforums_pkl = str(path_clean_data / \"daily_subforums.pkl\")\n",
    "# path_emote_pkl = str(path_clean_data / \"daily_emote_processed_{}.pkl\")\n",
    "# path_joined_pkl = str(path_clean_data / \"daily_joined_df.pkl\")\n",
    "# path_bigrams_pkl = str(path_corpus_pkl.format(\"all\", \"all\", \"daily_text_df\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Topic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "forum = \"special-needs\"\n",
    "group = \"all\"\n",
    "id_type = \"family_id\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary.load(path_dictionary_gensim.format(forum, group, id_type))\n",
    "corpus = pickle.load(open(path_corpus_pkl.format(forum, group, id_type), 'rb'))\n",
    "lemmatized_text = pickle.load(open(path_lemma_pkl.format(forum, group, id_type), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model finished time:  1.5097419102986653\n",
      "0.43178274529929883\n",
      "working time:  1.7702297886212668\n"
     ]
    }
   ],
   "source": [
    "# 15 topics has the highest coherence\n",
    "n_topics = 15\n",
    "start = time.time()\n",
    "lda = LdaModel(\n",
    "    corpus=corpus,\n",
    "    num_topics=n_topics,\n",
    "    id2word=dictionary,\n",
    "    random_state=238,\n",
    "    alpha=\"auto\",\n",
    "    eta=\"auto\"\n",
    ")\n",
    "print(\"model finished time: \", (time.time() - start) / 60)\n",
    "coherence_model_lda = CoherenceModel(model=lda, texts=lemmatized_text, dictionary=dictionary, coherence='c_v')\n",
    "print(coherence_model_lda.get_coherence())\n",
    "print(\"working time: \", (time.time() - start) / 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda.save(path_ntopic_models.format(forum, group, id_type, str(n_topics)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daily text to corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lemmatize_all as la"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary.load(path_dictionary_gensim.format(forum, group, id_type))\n",
    "clean_text = pd.read_pickle(path_text_pkl)\n",
    "clean_text.columns = ['user_url', 'day', 'text_clean', 'sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sn_users_sql = \"\"\"\n",
    "    SELECT DISTINCT p.user_url AS user_url\n",
    "    FROM posts AS p\n",
    "    LEFT JOIN threads AS t\n",
    "    ON t.id=p.thread_id\n",
    "    LEFT JOIN subforums AS s\n",
    "    ON s.id=t.subforum_id\n",
    "    WHERE s.forum_id=24\n",
    "\"\"\"\n",
    "conn = create_connection(path_db)\n",
    "sn_user_df = pd.read_sql_query(sn_users_sql, conn)\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_text = pd.merge(clean_text, sn_user_df, on=\"user_url\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "making bigrams\n",
      "time elapsed: 39.28419262568156\n",
      "bigrams to corpus\n",
      "time elapsed: 0.5153856674830118\n",
      "CPU times: user 45.3 s, sys: 5.76 s, total: 51.1 s\n",
      "Wall time: 39min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_bigrams, corpus = la.make_corpus(clean_text, dictionary, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bigrams.to_pickle(path_corpus_pkl.format(\"special-needs\", \"all\", \"daily_text_df\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(corpus, open(path_corpus_pkl.format(\"special-needs\", \"all\", \"daily_text\"), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus = pickle.load(open(path_corpus_pkl.format(\"special-needs\", \"all\", \"daily_text\"), 'rb'))\n",
    "# len(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daily text to topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_topics = 15\n",
    "lda = LdaModel.load(path_ntopic_models.format(forum, group, id_type, str(n_topics)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.matutils import corpus2csc\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000685</td>\n",
       "      <td>0.000344</td>\n",
       "      <td>0.069275</td>\n",
       "      <td>0.316988</td>\n",
       "      <td>0.000616</td>\n",
       "      <td>0.067188</td>\n",
       "      <td>0.000316</td>\n",
       "      <td>0.000862</td>\n",
       "      <td>0.005149</td>\n",
       "      <td>0.000224</td>\n",
       "      <td>0.347239</td>\n",
       "      <td>0.016753</td>\n",
       "      <td>0.055360</td>\n",
       "      <td>0.118760</td>\n",
       "      <td>0.000242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.011825</td>\n",
       "      <td>0.000363</td>\n",
       "      <td>0.001532</td>\n",
       "      <td>0.001431</td>\n",
       "      <td>0.000649</td>\n",
       "      <td>0.046162</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.000909</td>\n",
       "      <td>0.468074</td>\n",
       "      <td>0.000236</td>\n",
       "      <td>0.216788</td>\n",
       "      <td>0.002439</td>\n",
       "      <td>0.218197</td>\n",
       "      <td>0.030807</td>\n",
       "      <td>0.000256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001114</td>\n",
       "      <td>0.067358</td>\n",
       "      <td>0.002385</td>\n",
       "      <td>0.002210</td>\n",
       "      <td>0.001002</td>\n",
       "      <td>0.114225</td>\n",
       "      <td>0.029597</td>\n",
       "      <td>0.237355</td>\n",
       "      <td>0.361407</td>\n",
       "      <td>0.000364</td>\n",
       "      <td>0.068411</td>\n",
       "      <td>0.092779</td>\n",
       "      <td>0.002688</td>\n",
       "      <td>0.018710</td>\n",
       "      <td>0.000395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.163373</td>\n",
       "      <td>0.048176</td>\n",
       "      <td>0.002696</td>\n",
       "      <td>0.002527</td>\n",
       "      <td>0.001147</td>\n",
       "      <td>0.332729</td>\n",
       "      <td>0.000588</td>\n",
       "      <td>0.144790</td>\n",
       "      <td>0.102098</td>\n",
       "      <td>0.000417</td>\n",
       "      <td>0.051512</td>\n",
       "      <td>0.143494</td>\n",
       "      <td>0.003060</td>\n",
       "      <td>0.002943</td>\n",
       "      <td>0.000452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.137600</td>\n",
       "      <td>0.000267</td>\n",
       "      <td>0.001129</td>\n",
       "      <td>0.024300</td>\n",
       "      <td>0.064738</td>\n",
       "      <td>0.374783</td>\n",
       "      <td>0.000245</td>\n",
       "      <td>0.000669</td>\n",
       "      <td>0.193862</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>0.189324</td>\n",
       "      <td>0.001724</td>\n",
       "      <td>0.009772</td>\n",
       "      <td>0.001225</td>\n",
       "      <td>0.000188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0  0.000685  0.000344  0.069275  0.316988  0.000616  0.067188  0.000316   \n",
       "1  0.011825  0.000363  0.001532  0.001431  0.000649  0.046162  0.000333   \n",
       "2  0.001114  0.067358  0.002385  0.002210  0.001002  0.114225  0.029597   \n",
       "3  0.163373  0.048176  0.002696  0.002527  0.001147  0.332729  0.000588   \n",
       "4  0.137600  0.000267  0.001129  0.024300  0.064738  0.374783  0.000245   \n",
       "\n",
       "         7         8         9         10        11        12        13  \\\n",
       "0  0.000862  0.005149  0.000224  0.347239  0.016753  0.055360  0.118760   \n",
       "1  0.000909  0.468074  0.000236  0.216788  0.002439  0.218197  0.030807   \n",
       "2  0.237355  0.361407  0.000364  0.068411  0.092779  0.002688  0.018710   \n",
       "3  0.144790  0.102098  0.000417  0.051512  0.143494  0.003060  0.002943   \n",
       "4  0.000669  0.193862  0.000174  0.189324  0.001724  0.009772  0.001225   \n",
       "\n",
       "         14  \n",
       "0  0.000242  \n",
       "1  0.000256  \n",
       "2  0.000395  \n",
       "3  0.000452  \n",
       "4  0.000188  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_topics = lda.get_document_topics(corpus, minimum_probability=0.0)\n",
    "all_topics_csr = corpus2csc(all_topics)\n",
    "all_topics_numpy = all_topics_csr.T.toarray()\n",
    "all_topics_df = pd.DataFrame(all_topics_numpy)\n",
    "all_topics_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = [\"topic_{}\".format(i) for i in range(n_topics)]\n",
    "all_topics_df.columns = column_names\n",
    "all_topics_df.to_pickle(path_topics_pkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 644587 entries, 0 to 644665\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count   Dtype         \n",
      "---  ------    --------------   -----         \n",
      " 0   user_url  644587 non-null  object        \n",
      " 1   day       644587 non-null  datetime64[ns]\n",
      " 2   bigrams   644587 non-null  object        \n",
      "dtypes: datetime64[ns](1), object(2)\n",
      "memory usage: 19.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df_bigrams.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 644587 entries, 0 to 644586\n",
      "Data columns (total 15 columns):\n",
      " #   Column    Non-Null Count   Dtype  \n",
      "---  ------    --------------   -----  \n",
      " 0   topic_0   644587 non-null  float64\n",
      " 1   topic_1   644587 non-null  float64\n",
      " 2   topic_2   644587 non-null  float64\n",
      " 3   topic_3   644587 non-null  float64\n",
      " 4   topic_4   644587 non-null  float64\n",
      " 5   topic_5   644587 non-null  float64\n",
      " 6   topic_6   644587 non-null  float64\n",
      " 7   topic_7   644587 non-null  float64\n",
      " 8   topic_8   644587 non-null  float64\n",
      " 9   topic_9   644587 non-null  float64\n",
      " 10  topic_10  644587 non-null  float64\n",
      " 11  topic_11  644587 non-null  float64\n",
      " 12  topic_12  644587 non-null  float64\n",
      " 13  topic_13  644587 non-null  float64\n",
      " 14  topic_14  644587 non-null  float64\n",
      "dtypes: float64(15)\n",
      "memory usage: 73.8 MB\n"
     ]
    }
   ],
   "source": [
    "all_topics_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_topics_df = pd.concat([df_bigrams.reset_index(drop=True), all_topics_df.reset_index(drop=True)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_topics_df = all_topics_df.drop('bigrams', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_topics_df.to_pickle(path_topics_pkl)\n",
    "all_topics_df.to_csv(str(path_clean_data / \"daily_topics_sn.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_topics_df = pd.read_pickle(path_topics_pkl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Topic Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_list(fn, results):\n",
    "    with open(fn, 'a') as f:\n",
    "        writer = csv.writer(f) \n",
    "        writer.writerow(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_topics = 15\n",
    "lda = LdaModel.load(path_ntopic_models.format(forum, group, id_type, str(n_topics)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_words = 20\n",
    "topics = lda.print_topics(num_topics=n_topics, num_words=n_words)\n",
    "for topic in topics:\n",
    "    write_list(path_topics, [topic[0], topic[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Dominant Topic and Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_url</th>\n",
       "      <th>day</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abbey-h-18</td>\n",
       "      <td>2014-11-07</td>\n",
       "      <td>Hi, My little boy who just turned 4 past Septe...</td>\n",
       "      <td>{'neg': 0.042, 'neu': 0.855, 'pos': 0.102, 'co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abbey-h-18</td>\n",
       "      <td>2015-07-08</td>\n",
       "      <td>Hi Kaye, I can relate to you, my boy is starti...</td>\n",
       "      <td>{'neg': 0.109, 'neu': 0.737, 'pos': 0.154, 'co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abbey-h-18</td>\n",
       "      <td>2017-05-11</td>\n",
       "      <td>Hi Ladies, Just catching up on thread. My cram...</td>\n",
       "      <td>{'neg': 0.033, 'neu': 0.828, 'pos': 0.139, 'co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abbey-h-18</td>\n",
       "      <td>2017-06-16</td>\n",
       "      <td>yes me!! Im 9+5 and been suffering with bleedi...</td>\n",
       "      <td>{'neg': 0.05, 'neu': 0.87, 'pos': 0.08, 'compo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abbey-h-18</td>\n",
       "      <td>2014-08-31</td>\n",
       "      <td>We used to be £100-£120 per week around £400 p...</td>\n",
       "      <td>{'neg': 0.024, 'neu': 0.875, 'pos': 0.101, 'co...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_url        day                                         text_clean  \\\n",
       "0  abbey-h-18 2014-11-07  Hi, My little boy who just turned 4 past Septe...   \n",
       "1  abbey-h-18 2015-07-08  Hi Kaye, I can relate to you, my boy is starti...   \n",
       "2  abbey-h-18 2017-05-11  Hi Ladies, Just catching up on thread. My cram...   \n",
       "3  abbey-h-18 2017-06-16  yes me!! Im 9+5 and been suffering with bleedi...   \n",
       "4  abbey-h-18 2014-08-31  We used to be £100-£120 per week around £400 p...   \n",
       "\n",
       "                                           sentiment  \n",
       "0  {'neg': 0.042, 'neu': 0.855, 'pos': 0.102, 'co...  \n",
       "1  {'neg': 0.109, 'neu': 0.737, 'pos': 0.154, 'co...  \n",
       "2  {'neg': 0.033, 'neu': 0.828, 'pos': 0.139, 'co...  \n",
       "3  {'neg': 0.05, 'neu': 0.87, 'pos': 0.08, 'compo...  \n",
       "4  {'neg': 0.024, 'neu': 0.875, 'pos': 0.101, 'co...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_url</th>\n",
       "      <th>day</th>\n",
       "      <th>topic_0</th>\n",
       "      <th>topic_1</th>\n",
       "      <th>topic_2</th>\n",
       "      <th>topic_3</th>\n",
       "      <th>topic_4</th>\n",
       "      <th>topic_5</th>\n",
       "      <th>topic_6</th>\n",
       "      <th>topic_7</th>\n",
       "      <th>topic_8</th>\n",
       "      <th>topic_9</th>\n",
       "      <th>topic_10</th>\n",
       "      <th>topic_11</th>\n",
       "      <th>topic_12</th>\n",
       "      <th>topic_13</th>\n",
       "      <th>topic_14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abbey-h-18</td>\n",
       "      <td>2014-11-07</td>\n",
       "      <td>0.000685</td>\n",
       "      <td>0.000344</td>\n",
       "      <td>0.069275</td>\n",
       "      <td>0.316988</td>\n",
       "      <td>0.000616</td>\n",
       "      <td>0.067188</td>\n",
       "      <td>0.000316</td>\n",
       "      <td>0.000862</td>\n",
       "      <td>0.005149</td>\n",
       "      <td>0.000224</td>\n",
       "      <td>0.347239</td>\n",
       "      <td>0.016753</td>\n",
       "      <td>0.055360</td>\n",
       "      <td>0.118760</td>\n",
       "      <td>0.000242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abbey-h-18</td>\n",
       "      <td>2015-07-08</td>\n",
       "      <td>0.011825</td>\n",
       "      <td>0.000363</td>\n",
       "      <td>0.001532</td>\n",
       "      <td>0.001431</td>\n",
       "      <td>0.000649</td>\n",
       "      <td>0.046162</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.000909</td>\n",
       "      <td>0.468074</td>\n",
       "      <td>0.000236</td>\n",
       "      <td>0.216788</td>\n",
       "      <td>0.002439</td>\n",
       "      <td>0.218197</td>\n",
       "      <td>0.030807</td>\n",
       "      <td>0.000256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abbey-h-18</td>\n",
       "      <td>2017-05-11</td>\n",
       "      <td>0.001114</td>\n",
       "      <td>0.067358</td>\n",
       "      <td>0.002385</td>\n",
       "      <td>0.002210</td>\n",
       "      <td>0.001002</td>\n",
       "      <td>0.114225</td>\n",
       "      <td>0.029597</td>\n",
       "      <td>0.237355</td>\n",
       "      <td>0.361407</td>\n",
       "      <td>0.000364</td>\n",
       "      <td>0.068411</td>\n",
       "      <td>0.092779</td>\n",
       "      <td>0.002688</td>\n",
       "      <td>0.018710</td>\n",
       "      <td>0.000395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abbey-h-18</td>\n",
       "      <td>2017-06-16</td>\n",
       "      <td>0.163373</td>\n",
       "      <td>0.048176</td>\n",
       "      <td>0.002696</td>\n",
       "      <td>0.002527</td>\n",
       "      <td>0.001147</td>\n",
       "      <td>0.332729</td>\n",
       "      <td>0.000588</td>\n",
       "      <td>0.144790</td>\n",
       "      <td>0.102098</td>\n",
       "      <td>0.000417</td>\n",
       "      <td>0.051512</td>\n",
       "      <td>0.143494</td>\n",
       "      <td>0.003060</td>\n",
       "      <td>0.002943</td>\n",
       "      <td>0.000452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abbey-h-18</td>\n",
       "      <td>2014-08-31</td>\n",
       "      <td>0.137600</td>\n",
       "      <td>0.000267</td>\n",
       "      <td>0.001129</td>\n",
       "      <td>0.024300</td>\n",
       "      <td>0.064738</td>\n",
       "      <td>0.374783</td>\n",
       "      <td>0.000245</td>\n",
       "      <td>0.000669</td>\n",
       "      <td>0.193862</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>0.189324</td>\n",
       "      <td>0.001724</td>\n",
       "      <td>0.009772</td>\n",
       "      <td>0.001225</td>\n",
       "      <td>0.000188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_url        day   topic_0   topic_1   topic_2   topic_3   topic_4  \\\n",
       "0  abbey-h-18 2014-11-07  0.000685  0.000344  0.069275  0.316988  0.000616   \n",
       "1  abbey-h-18 2015-07-08  0.011825  0.000363  0.001532  0.001431  0.000649   \n",
       "2  abbey-h-18 2017-05-11  0.001114  0.067358  0.002385  0.002210  0.001002   \n",
       "3  abbey-h-18 2017-06-16  0.163373  0.048176  0.002696  0.002527  0.001147   \n",
       "4  abbey-h-18 2014-08-31  0.137600  0.000267  0.001129  0.024300  0.064738   \n",
       "\n",
       "    topic_5   topic_6   topic_7   topic_8   topic_9  topic_10  topic_11  \\\n",
       "0  0.067188  0.000316  0.000862  0.005149  0.000224  0.347239  0.016753   \n",
       "1  0.046162  0.000333  0.000909  0.468074  0.000236  0.216788  0.002439   \n",
       "2  0.114225  0.029597  0.237355  0.361407  0.000364  0.068411  0.092779   \n",
       "3  0.332729  0.000588  0.144790  0.102098  0.000417  0.051512  0.143494   \n",
       "4  0.374783  0.000245  0.000669  0.193862  0.000174  0.189324  0.001724   \n",
       "\n",
       "   topic_12  topic_13  topic_14  \n",
       "0  0.055360  0.118760  0.000242  \n",
       "1  0.218197  0.030807  0.000256  \n",
       "2  0.002688  0.018710  0.000395  \n",
       "3  0.003060  0.002943  0.000452  \n",
       "4  0.009772  0.001225  0.000188  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_topics_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['user_url', 'day', 'topic_0', 'topic_1', 'topic_2', 'topic_3',\n",
       "       'topic_4', 'topic_5', 'topic_6', 'topic_7', 'topic_8', 'topic_9',\n",
       "       'topic_10', 'topic_11', 'topic_12', 'topic_13', 'topic_14'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_topics_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_topics_df['dominant_topic'] = all_topics_df[['topic_0', 'topic_1', 'topic_2', 'topic_3',\n",
    "       'topic_4', 'topic_5', 'topic_6', 'topic_7', 'topic_8', 'topic_9',\n",
    "       'topic_10', 'topic_11', 'topic_12', 'topic_13', 'topic_14']].idxmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "topic_8     264693\n",
       "topic_10    194879\n",
       "topic_5      64503\n",
       "topic_11     46937\n",
       "topic_7      22433\n",
       "topic_2      14501\n",
       "topic_3      14017\n",
       "topic_0       8029\n",
       "topic_12      6642\n",
       "topic_13      5163\n",
       "topic_4       2182\n",
       "topic_1        352\n",
       "topic_6        160\n",
       "topic_14        61\n",
       "topic_9         35\n",
       "Name: dominant_topic, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_topics_df['dominant_topic'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_topics_text = pd.merge(all_topics_df, clean_text[['user_url','day','text_clean']], on=['user_url','day'], how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_topics_text.to_csv(str(path_clean_data / \"sn_topics_and_text.csv\"), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

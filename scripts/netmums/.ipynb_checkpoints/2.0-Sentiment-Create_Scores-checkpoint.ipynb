{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Sentiment for Netmums"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from pathlib import Path\n",
    "from scraping import create_connection\n",
    "from tqdm.notebook import tqdm\n",
    "from math import floor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Path.cwd()\n",
    "path_parent = p.parents[1]\n",
    "path_db = str(path_parent / \"database\" / \"netmums-merged.db\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_size(conn):\n",
    "    \"\"\" gets the size of the data set in number of rows\n",
    "    :param conn: connection the the db\n",
    "    :return size: size of the posts table\n",
    "    \"\"\"\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(''' SELECT COUNT(id) FROM posts ''')\n",
    "    size = cur.fetchone()\n",
    "    if size:\n",
    "        return int(size[0])\n",
    "    raise SystemExit(\"No size found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(chunksize):\n",
    "    \"\"\" read data in chunks from the table, format the text,\n",
    "        apply the sentiemnt analyzer, and write chunks to \n",
    "        the sentiment table\n",
    "    :param chunksize: size of chunks\n",
    "    \"\"\"\n",
    "    sql = ''' SELECT * FROM text '''\n",
    "    reader = pd.read_sql_query(sql,\n",
    "                               conn,\n",
    "                               chunksize=chunksize)\n",
    "    for i, df in enumerate(tqdm(reader)):\n",
    "        df = gen_sentiment(df, 'text_clean', 'clean')\n",
    "        df.drop('text_clean', axis=1, inplace=True)\n",
    "        if i == 0:\n",
    "            df.to_sql('sentiment', conn, if_exists='replace', index=False)\n",
    "        else:\n",
    "            df.to_sql('sentiment', conn, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data_month():\n",
    "    \"\"\" read data in chunks from the table, format the text,\n",
    "        apply the sentiemnt analyzer, and write chunks to \n",
    "        the sentiment table\n",
    "    :param chunksize: size of chunks\n",
    "    \"\"\"\n",
    "    sql = '''\n",
    "        SELECT t.post_id, t.text_clean, p.user_url, p.date_created\n",
    "        FROM posts AS p\n",
    "        LEFT JOIN text AS t\n",
    "        ON t.post_id = p.id\n",
    "        WHERE p.date_created >= '{0}' AND p.date_created < '{1}'\n",
    "    '''\n",
    "    months = range(1, 13)\n",
    "    years = range(2014, 2021)\n",
    "    for year in tqdm(years):\n",
    "        for month in tqdm(months, leave=False):\n",
    "            begin_date = \"{0}-{1}-01 00:00AM\".format(year, str(month).zfill(2))\n",
    "            end_date = \"{0}-{1}-01 00:00AM\".format(year, str(month + 1).zfill(2))\n",
    "            sql = '''\n",
    "                SELECT t.post_id, t.text_clean, p.user_url, p.date_created\n",
    "                FROM posts AS p\n",
    "                LEFT JOIN text AS t\n",
    "                ON t.post_id = p.id\n",
    "                WHERE p.date_created >= '{0}' AND p.date_created < '{1}'\n",
    "            '''\n",
    "            df = pd.read_sql_query(sql.format(begin_date, end_date), conn)\n",
    "            df = df.loc[df['user_url'] != \"Anonymous\"]\n",
    "            df = df.loc[(df['text_clean'] != \"\") & ~(df['text_clean'].isnull())]\n",
    "            df['text_month'] = df.sort_values(['user_url','date_created']).groupby('user_url')['text_clean'].transform(lambda x : ' \\n'.join(x))\n",
    "            df = df[['user_url', 'text_month']].drop_duplicates().reset_index(drop=True)\n",
    "            name = \"month\"\n",
    "            name_neg = \"neg_sen_{}\".format(name)\n",
    "            name_neu = \"neu_sen_{}\".format(name)\n",
    "            name_pos = \"pos_sen_{}\".format(name)\n",
    "            name_com = \"com_sen_{}\".format(name)\n",
    "            df[name_neg] = 0\n",
    "            df[name_neu] = 0\n",
    "            df[name_pos] = 0\n",
    "            df[name_com] = 0\n",
    "            for index, row in df.iterrows():\n",
    "                sentiment = sentiment_scores(row['text_month'], analyzer)\n",
    "                df.loc[index, name_neg] = sentiment['neg']\n",
    "                df.loc[index, name_neu] = sentiment['neu']\n",
    "                df.loc[index, name_pos] = sentiment['pos']\n",
    "                df.loc[index, name_com] = sentiment['compound']\n",
    "            df['year'] = year\n",
    "            df['month'] = month\n",
    "            if month == 1 and year == 2014:\n",
    "                df.to_sql('month_sentiment', conn, if_exists='replace', index=False)\n",
    "            else:\n",
    "                df.to_sql('month_sentiment', conn, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_sentiment(df, var, name):\n",
    "    \"\"\" apply the sentiment score to the input var\n",
    "    :param var: string name of column getting sentiment for\n",
    "    :param name: string variable suffix\n",
    "    :return score: a dictionary of scores (neg, neu, pos, compound)\n",
    "    \"\"\"\n",
    "    sentiment = df[var].apply(lambda x: sentiment_scores(x, analyzer))\n",
    "    name_neg = \"neg_sen_{}\".format(name)\n",
    "    name_neu = \"neu_sen_{}\".format(name)\n",
    "    name_pos = \"pos_sen_{}\".format(name)\n",
    "    name_com = \"com_sen_{}\".format(name)\n",
    "    df[name_neg] = sentiment.apply(lambda x: x.get('neg', 0))\n",
    "    df[name_neu] = sentiment.apply(lambda x: x.get('neu', 0))\n",
    "    df[name_pos] = sentiment.apply(lambda x: x.get('pos', 0))\n",
    "    df[name_com] = sentiment.apply(lambda x: x.get('compound', 0))\n",
    "    del sentiment\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_sentiment_monthly(df, var, name):\n",
    "    \"\"\" apply the sentiment score to the input var\n",
    "    :param var: string name of column getting sentiment for\n",
    "    :param name: string variable suffix\n",
    "    :return score: a dictionary of scores (neg, neu, pos, compound)\n",
    "    \"\"\"\n",
    "    name_neg = \"neg_sen_{}\".format(name)\n",
    "    name_neu = \"neu_sen_{}\".format(name)\n",
    "    name_pos = \"pos_sen_{}\".format(name)\n",
    "    name_com = \"com_sen_{}\".format(name)\n",
    "    df[name_neg] = 0\n",
    "    df[name_neu] = 0\n",
    "    df[name_pos] = 0\n",
    "    df[name_com] = 0\n",
    "    for index, row in df.iterrows():\n",
    "        sentiment = sentiment_scores(row['text_month'], analyzer)\n",
    "        df.loc[index, name_neg] = sentiment['neg']\n",
    "        df.loc[index, name_neu] = sentiment['neu']\n",
    "        df.loc[index, name_pos] = sentiment['pos']\n",
    "        df.loc[index, name_com] = sentiment['compound']\n",
    "        if index % 100 == 0:\n",
    "            print(index)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_scores(sentence, analyzer):\n",
    "    \"\"\" create sentiment scores with the VADER analyzer\n",
    "    :param sentence: sentence to create scores for\n",
    "    :param analyzer: VADER sentiment analyzer\n",
    "    :return score: a dictionary of scores (neg, neu, pos, compound)\n",
    "    \"\"\"\n",
    "    score = analyzer.polarity_scores(sentence)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Loop through chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = create_connection(path_db)\n",
    "size = get_size(conn)\n",
    "nchunks = 200\n",
    "chunksize = floor(size / nchunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process_data(chunksize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c321d8f391b410b8e1105f473d4a40a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "process_data_month()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.commit()\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

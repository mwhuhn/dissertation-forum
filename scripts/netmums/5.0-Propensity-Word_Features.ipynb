{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Word Features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LDA\n",
    "from gensim import corpora, models\n",
    "from gensim.models import CoherenceModel, LdaModel, LdaMulticore\n",
    "from gensim.models.callbacks import PerplexityMetric, ConvergenceMetric, CoherenceMetric\n",
    "# Managing data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "# DB connection\n",
    "from scraping import create_connection\n",
    "# Files & I/O\n",
    "import pickle\n",
    "import csv\n",
    "import os\n",
    "from pathlib import Path\n",
    "from io import FileIO\n",
    "# For logging\n",
    "import logging\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "# Random\n",
    "import random\n",
    "# Parallelizing\n",
    "import dask.dataframe as dd\n",
    "from dask.multiprocessing import get"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Path.cwd()\n",
    "path_parent = p.parents[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# database\n",
    "path_db = str(path_parent / \"database\" / \"netmums-merged.db\")\n",
    "path_clean_data = path_parent / \"clean_data\" / \"netmums\"\n",
    "# data to load\n",
    "path_lemma_pkl = str(path_clean_data / \"lemmatized_text_{0}_{1}_{2}.pkl\")\n",
    "path_corpus_pkl = str(path_clean_data / \"corpus_{0}_{1}_{2}.pkl\")\n",
    "path_dictionary_gensim = str(path_clean_data / \"dictionary_{0}_{1}_{2}.gensim\")\n",
    "# model saving\n",
    "path_tune_models = str(path_clean_data / \"lda_tune_{0}_{1}_{2}_{3}_{4}.gensim\")\n",
    "path_ntopic_models = str(path_clean_data / \"lda_ntopics_{0}_{1}_{2}_{3}.gensim\")\n",
    "# path_coherence = str(path_parent / \"clean_data\" / \"coherence_{}.csv\")\n",
    "path_log = str(path_clean_data / \"logging_{0}_{1}_{2}_{3}.log\")\n",
    "path_log_iterations = str(path_clean_data / \"logging_{0}_{1}_{2}_{3}.log\")\n",
    "# dominant topic\n",
    "path_dom_topic = str(path_clean_data / \"dominant_topic_{0}_{1}_{2}_{3}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframes\n",
    "path_topics_pkl = str(path_clean_data / \"daily_topics.pkl\")\n",
    "path_text_pkl = str(path_clean_data / \"daily_clean_text.pkl\")\n",
    "path_days_since_pkl = str(path_clean_data / \"daily_days_since.pkl\")\n",
    "path_subforums_pkl = str(path_clean_data / \"daily_subforums.pkl\")\n",
    "path_emote_pkl = str(path_clean_data / \"daily_emote_processed_{}.pkl\")\n",
    "path_joined_pkl = str(path_clean_data / \"daily_joined_df.pkl\")\n",
    "path_bigrams_pkl = str(path_corpus_pkl.format(\"all\", \"all\", \"daily_text_df\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process all text for topics\n",
    "Make lemmatized text, dictionary, and corpus for all text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import lemmatize_all as la\n",
    "# la.process_data(chunksize=1000000, n_chunks=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make corpuses for all text chunk. The prior command didn't create individual corpuses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_chunks = 4\n",
    "# for i in tqdm(range(16)):\n",
    "#     text = pickle.load(open(path_lemma_pkl.format(\"all\", \"all\", \"thread_id_{}\".format(i)), 'rb'))\n",
    "#     corpus = la.text_to_corpus(text, n_chunks, dictionary)\n",
    "#     pickle.dump(corpus, open(path_corpus_pkl.format(\"all\", \"all\", \"thread_id_{}\".format(i)), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_chunks = 10\n",
    "for i in tqdm(range(16)):\n",
    "    text = pickle.load(open(path_lemma_pkl.format(\"all\", \"all\", \"message_id_{}\".format(i)), 'rb'))\n",
    "    corpus = la.text_to_corpus(text, n_chunks, dictionary)\n",
    "    pickle.dump(corpus, open(path_corpus_pkl.format(\"all\", \"all\", \"message_id_{}\".format(i)), 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make single corpus using the whole dictionary. The process_data command didn't create a good corpus using the incremental approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_chunks = 4\n",
    "# corpus = []\n",
    "# for i in tqdm(range(16)):\n",
    "#     text = pickle.load(open(path_lemma_pkl.format(\"all\", \"all\", \"thread_id_{}\".format(i)), 'rb'))\n",
    "#     corpus = corpus + la.text_to_corpus(text, n_chunks, dictionary)\n",
    "# pickle.dump(corpus, open(path_corpus_pkl.format(\"all\", \"all\", \"thread_id_v2\"), 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make 10% sample lemmatized text and corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from tqdm import tqdm\n",
    "import lemmatize_all as la"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary.load(path_dictionary_gensim.format(\"all\", \"all\", \"thread_id\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatized_text = []\n",
    "corpus = []\n",
    "n_chunks = 1\n",
    "for i in tqdm(range(16)):\n",
    "    text = pickle.load(open(path_lemma_pkl.format(\"all\", \"all\", \"thread_id_{}\".format(i)), 'rb'))\n",
    "    list_len = len(text)\n",
    "    list_10p = int(list_len * .1)\n",
    "    text = random.sample(text, list_10p)\n",
    "    lemmatized_text = lemmatized_text + text\n",
    "    corpus = corpus + la.text_to_corpus(text, n_chunks, dictionary)\n",
    "pickle.dump(lemmatized_text, open(path_lemma_pkl.format(\"all\", \"all\", \"thread_id_10p\"), 'wb'))\n",
    "pickle.dump(corpus, open(path_corpus_pkl.format(\"all\", \"all\", \"thread_id_10p\"), 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Topic Model for 10% sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary.load(path_dictionary_gensim.format(\"all\", \"all\", \"thread_id\"))\n",
    "corpus = pickle.load(open(path_corpus_pkl.format(\"all\", \"all\", \"thread_id_10p\"), 'rb'))\n",
    "lemmatized_text = pickle.load(open(path_lemma_pkl.format(\"all\", \"all\", \"thread_id_10p\".format(2)), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "n_topics = 20\n",
    "lda = LdaModel(\n",
    "    corpus=corpus,\n",
    "    num_topics=n_topics,\n",
    "    id2word=dictionary,\n",
    "    random_state=1,\n",
    "    alpha=\"auto\",\n",
    "    eta=\"auto\"\n",
    ")\n",
    "coherence_model_lda = CoherenceModel(model=lda, texts=lemmatized_text, dictionary=dictionary, coherence='c_v')\n",
    "print(coherence_model_lda.get_coherence())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda.save(path_ntopic_models.format(\"all\", \"all\", \"thread_id_10p\", str(n_topics)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daily text to corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lemmatize_all as la"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary.load(path_dictionary_gensim.format(\"all\", \"all\", \"thread_id\"))\n",
    "clean_text = pd.read_pickle(path_text_pkl)\n",
    "clean_text.columns = ['user_url', 'day', 'text_clean', 'sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_bigrams, corpus = la.make_corpus(clean_text, dictionary, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bigrams.to_pickle(path_corpus_pkl.format(\"all\", \"all\", \"daily_text_df\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(corpus, open(path_corpus_pkl.format(\"all\", \"all\", \"daily_text\"), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus = pickle.load(open(path_corpus_pkl.format(\"all\", \"all\", \"daily_text\"), 'rb'))\n",
    "# len(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daily text to topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_topics = 20\n",
    "lda = LdaModel.load(path_ntopic_models.format(\"all\", \"all\", \"thread_id_10p\", str(n_topics)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.matutils import corpus2csc\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_topics = lda.get_document_topics(corpus, minimum_probability=0.0)\n",
    "all_topics_csr = corpus2csc(all_topics)\n",
    "all_topics_numpy = all_topics_csr.T.toarray()\n",
    "all_topics_df = pd.DataFrame(all_topics_numpy)\n",
    "all_topics_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = [\"topic_{}\".format(i) for i in range(20)]\n",
    "all_topics_df.columns = column_names\n",
    "all_topics_df.to_pickle(path_topics_pkl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = '''\n",
    "    SELECT\n",
    "        text.text_clean AS text_clean,\n",
    "        s.name AS subforum_name,\n",
    "        p.user_url AS user_url,\n",
    "        p.date_created AS date_created\n",
    "    FROM text\n",
    "    LEFT JOIN posts AS p\n",
    "    ON text.post_id = p.id\n",
    "    LEFT JOIN threads AS t\n",
    "    ON t.id=p.thread_id\n",
    "    LEFT JOIN subforums AS s\n",
    "    ON s.id=t.subforum_id\n",
    "    LEFT JOIN forums AS f\n",
    "    ON f.id=s.forum_id\n",
    "    WHERE text.text_clean<>\"\"\n",
    "    AND p.user_url<>\"Anonymous\"\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = create_connection(path_db)\n",
    "df = pd.read_sql_query(sql, conn)\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create days dataframe\n",
    "ddf = dd.from_pandas(df, npartitions=200)\n",
    "ddf['date_created'] = dd.to_datetime(ddf['date_created'])\n",
    "ddf['day'] = ddf['date_created'].dt.date\n",
    "df = ddf.compute(scheduler='processes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count unique days in dataset\n",
    "ddf = dd.from_pandas(df, npartitions=200)\n",
    "ddf = ddf[['user_url', 'day']].groupby([\"user_url\"])[\"day\"].nunique().reset_index(drop=False)\n",
    "df_count = ddf.compute(scheduler='processes')\n",
    "df_count.columns = ['user_url','n_unique_days']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count posts per day\n",
    "ddf = dd.from_pandas(df, npartitions=200)\n",
    "ddf = ddf.groupby([\"user_url\", \"day\"])['subforum_name'].count().reset_index(drop=False)\n",
    "df_daily_count = ddf.compute(scheduler='processes')\n",
    "df_daily_count.columns = ['user_url', 'day', 'n_posts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_daily_count['day'] = df_daily_count['day'].apply(lambda x: x.strftime('%Y-%m-%d'))\n",
    "df_daily_count.to_stata(path_clean_data / \"daily_panel_counts.dta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morethanone = df_count.loc[df_count['n_unique_days'] > 1, 'user_url']\n",
    "df = df.loc[df['user_url'].isin(morethanone)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop=True, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# days since last post\n",
    "ddf = dd.from_pandas(df, npartitions=200)\n",
    "ddf = ddf[['user_url', 'day']].groupby([\"user_url\", \"day\"])['day'].count().to_frame().rename(columns={'day':'daily_count'}).reset_index(drop=False).sort_values(['user_url', 'day'])\n",
    "df_days_since = ddf.compute(scheduler='processes')\n",
    "df_days_since['datediff'] = df_days_since[['user_url', 'day', 'daily_count']].groupby(['user_url'])['day'].diff()\n",
    "df_days_since['days_since_last_post'] = 0\n",
    "df_days_since.loc[df_days_since['datediff'].notna(), 'days_since_last_post'] = df_days_since.loc[df_days_since['datediff'].notna(), 'datediff'].apply(lambda x: x.days)\n",
    "df_days_since = df_days_since.drop(\"datediff\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_days_since.to_pickle(path_days_since_pkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_days_since.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forum posted in\n",
    "df_subforums = df[['user_url', 'day', 'subforum_name']].groupby([\"user_url\", \"day\", \"subforum_name\"])[\"subforum_name\"].count().reset_index(name=\"count\")\n",
    "df_subforums = df_subforums.pivot(index=['user_url', 'day'], columns='subforum_name', values='count').reset_index(drop=False).fillna(0).reset_index(drop=True)\n",
    "df_subforums.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subforums.to_pickle(path_subforums_pkl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Join Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_days_since = pd.read_pickle(path_days_since_pkl)\n",
    "df_subforums = pd.read_pickle(path_subforums_pkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_emote_0 = pd.read_pickle(path_emote_pkl.format(0))\n",
    "df_emote_1 = pd.read_pickle(path_emote_pkl.format(1))\n",
    "df_emote_2 = pd.read_pickle(path_emote_pkl.format(2))\n",
    "df_emote_0 = df_emote_0.drop(\"scores\", axis=1)\n",
    "df_emote_1 = df_emote_1.drop(\"scores\", axis=1)\n",
    "df_emote_2 = df_emote_2.drop(\"scores\", axis=1)\n",
    "df_emote = pd.concat([df_emote_0, df_emote_1, df_emote_2], axis=0).reset_index(drop=True)\n",
    "df_emote['day'] = df_emote['day'].apply(lambda x: x.date())\n",
    "df_emote = df_emote.groupby(['user_url', 'day']).agg(anger=(\"anger\", np.mean),\n",
    "                                          joy=(\"joy\", np.mean),\n",
    "                                          optimism=(\"optimism\", np.mean),\n",
    "                                          sadness=(\"sadness\", np.mean)).reset_index(drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_url</th>\n",
       "      <th>day</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>150</td>\n",
       "      <td>2015-10-21</td>\n",
       "      <td>Hi I didn't get into carrying until ds 2 was a...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.774, 'pos': 0.226, 'comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>150</td>\n",
       "      <td>2016-05-20</td>\n",
       "      <td>I have low iron in normal life although convin...</td>\n",
       "      <td>{'neg': 0.16, 'neu': 0.795, 'pos': 0.045, 'com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1st-time-mummy</td>\n",
       "      <td>2018-10-30</td>\n",
       "      <td>Hi Helen I just wondered how your little boy i...</td>\n",
       "      <td>{'neg': 0.119, 'neu': 0.833, 'pos': 0.048, 'co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24h</td>\n",
       "      <td>2018-12-30</td>\n",
       "      <td>Did you get your positive opk Siobhan? Hi Clai...</td>\n",
       "      <td>{'neg': 0.092, 'neu': 0.68, 'pos': 0.228, 'com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2557</td>\n",
       "      <td>2015-10-19</td>\n",
       "      <td>Sian Are you alright now? Hope everything is o...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.507, 'pos': 0.493, 'comp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_url        day  \\\n",
       "0             150 2015-10-21   \n",
       "1             150 2016-05-20   \n",
       "2  1st-time-mummy 2018-10-30   \n",
       "3             24h 2018-12-30   \n",
       "4            2557 2015-10-19   \n",
       "\n",
       "                                                text  \\\n",
       "0  Hi I didn't get into carrying until ds 2 was a...   \n",
       "1  I have low iron in normal life although convin...   \n",
       "2  Hi Helen I just wondered how your little boy i...   \n",
       "3  Did you get your positive opk Siobhan? Hi Clai...   \n",
       "4  Sian Are you alright now? Hope everything is o...   \n",
       "\n",
       "                                           sentiment  \n",
       "0  {'neg': 0.0, 'neu': 0.774, 'pos': 0.226, 'comp...  \n",
       "1  {'neg': 0.16, 'neu': 0.795, 'pos': 0.045, 'com...  \n",
       "2  {'neg': 0.119, 'neu': 0.833, 'pos': 0.048, 'co...  \n",
       "3  {'neg': 0.092, 'neu': 0.68, 'pos': 0.228, 'com...  \n",
       "4  {'neg': 0.0, 'neu': 0.507, 'pos': 0.493, 'comp...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sentiment = pd.read_pickle(path_text_pkl)\n",
    "df_sentiment = df_sentiment.drop(\"text\", axis=1)\n",
    "df_sentiment[['neg', 'neu', 'pos','compound']] = df_sentiment['sentiment'].apply(pd.Series)\n",
    "df_sentiment = df_sentiment.drop(\"sentiment\", axis=1)\n",
    "df_sentiment['day'] = df_sentiment['day'].apply(lambda x: x.date())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bigrams = pd.read_pickle(path_bigrams_pkl)\n",
    "df_topics = pd.read_pickle(path_topics_pkl)\n",
    "df_topics = pd.concat([df_bigrams.reset_index(drop=True), df_topics.reset_index(drop=True)], axis=1).drop('bigrams', axis=1)\n",
    "df_topics['day'] = df_topics['day'].apply(lambda x: x.date())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_sentiment.merge(df_emote, how=\"inner\", on=[\"user_url\",\"day\"])\n",
    "df = df.merge(df_subforums, how=\"inner\", on=[\"user_url\",\"day\"])\n",
    "df = df.merge(df_days_since, how=\"inner\", on=[\"user_url\",\"day\"])\n",
    "df = df.merge(df_topics, how=\"inner\", on=[\"user_url\",\"day\"])\n",
    "df.to_pickle(path_joined_pkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(path_joined_pkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_url</th>\n",
       "      <th>day</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "      <th>anger</th>\n",
       "      <th>joy</th>\n",
       "      <th>optimism</th>\n",
       "      <th>sadness</th>\n",
       "      <th>...</th>\n",
       "      <th>topic_17</th>\n",
       "      <th>topic_18</th>\n",
       "      <th>topic_19</th>\n",
       "      <th>sn_user</th>\n",
       "      <th>user_id</th>\n",
       "      <th>time_period</th>\n",
       "      <th>first_period</th>\n",
       "      <th>last_period</th>\n",
       "      <th>time_since_first_period</th>\n",
       "      <th>is_last_period</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1180372</th>\n",
       "      <td>alrx1</td>\n",
       "      <td>2014-02-20</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.814</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.9707</td>\n",
       "      <td>0.260971</td>\n",
       "      <td>0.056864</td>\n",
       "      <td>0.072216</td>\n",
       "      <td>0.609949</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.545847</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>1</td>\n",
       "      <td>2183</td>\n",
       "      <td>3182</td>\n",
       "      <td>2957</td>\n",
       "      <td>4719</td>\n",
       "      <td>225</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751159</th>\n",
       "      <td>alrx1</td>\n",
       "      <td>2014-03-25</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.610</td>\n",
       "      <td>0.390</td>\n",
       "      <td>0.9821</td>\n",
       "      <td>0.009462</td>\n",
       "      <td>0.964755</td>\n",
       "      <td>0.014913</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000359</td>\n",
       "      <td>0.015341</td>\n",
       "      <td>0.000348</td>\n",
       "      <td>1</td>\n",
       "      <td>2183</td>\n",
       "      <td>3215</td>\n",
       "      <td>2957</td>\n",
       "      <td>4719</td>\n",
       "      <td>258</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1159025</th>\n",
       "      <td>alrx1</td>\n",
       "      <td>2014-03-26</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.567</td>\n",
       "      <td>0.364</td>\n",
       "      <td>0.9730</td>\n",
       "      <td>0.013523</td>\n",
       "      <td>0.924859</td>\n",
       "      <td>0.047491</td>\n",
       "      <td>0.014127</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000474</td>\n",
       "      <td>0.248984</td>\n",
       "      <td>0.000458</td>\n",
       "      <td>1</td>\n",
       "      <td>2183</td>\n",
       "      <td>3216</td>\n",
       "      <td>2957</td>\n",
       "      <td>4719</td>\n",
       "      <td>259</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1394373</th>\n",
       "      <td>alrx1</td>\n",
       "      <td>2014-03-27</td>\n",
       "      <td>0.214</td>\n",
       "      <td>0.588</td>\n",
       "      <td>0.198</td>\n",
       "      <td>-0.3267</td>\n",
       "      <td>0.022793</td>\n",
       "      <td>0.035690</td>\n",
       "      <td>0.012705</td>\n",
       "      <td>0.928812</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.005351</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>1</td>\n",
       "      <td>2183</td>\n",
       "      <td>3217</td>\n",
       "      <td>2957</td>\n",
       "      <td>4719</td>\n",
       "      <td>260</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429723</th>\n",
       "      <td>alrx1</td>\n",
       "      <td>2014-04-07</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.9451</td>\n",
       "      <td>0.007536</td>\n",
       "      <td>0.964907</td>\n",
       "      <td>0.015495</td>\n",
       "      <td>0.012063</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000643</td>\n",
       "      <td>0.025142</td>\n",
       "      <td>0.000623</td>\n",
       "      <td>1</td>\n",
       "      <td>2183</td>\n",
       "      <td>3228</td>\n",
       "      <td>2957</td>\n",
       "      <td>4719</td>\n",
       "      <td>271</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1919442</th>\n",
       "      <td>alrx1</td>\n",
       "      <td>2014-04-19</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.763</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.9495</td>\n",
       "      <td>0.062314</td>\n",
       "      <td>0.085534</td>\n",
       "      <td>0.061200</td>\n",
       "      <td>0.790952</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>0.006527</td>\n",
       "      <td>0.000148</td>\n",
       "      <td>1</td>\n",
       "      <td>2183</td>\n",
       "      <td>3240</td>\n",
       "      <td>2957</td>\n",
       "      <td>4719</td>\n",
       "      <td>283</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597890</th>\n",
       "      <td>alrx1</td>\n",
       "      <td>2014-05-02</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.803</td>\n",
       "      <td>0.197</td>\n",
       "      <td>0.8900</td>\n",
       "      <td>0.015495</td>\n",
       "      <td>0.907554</td>\n",
       "      <td>0.050404</td>\n",
       "      <td>0.026547</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000351</td>\n",
       "      <td>0.022017</td>\n",
       "      <td>0.000340</td>\n",
       "      <td>1</td>\n",
       "      <td>2183</td>\n",
       "      <td>3253</td>\n",
       "      <td>2957</td>\n",
       "      <td>4719</td>\n",
       "      <td>296</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1726961</th>\n",
       "      <td>alrx1</td>\n",
       "      <td>2014-05-13</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.8645</td>\n",
       "      <td>0.051312</td>\n",
       "      <td>0.769607</td>\n",
       "      <td>0.090021</td>\n",
       "      <td>0.089060</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000419</td>\n",
       "      <td>0.020138</td>\n",
       "      <td>0.000405</td>\n",
       "      <td>1</td>\n",
       "      <td>2183</td>\n",
       "      <td>3264</td>\n",
       "      <td>2957</td>\n",
       "      <td>4719</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1126868</th>\n",
       "      <td>alrx1</td>\n",
       "      <td>2014-05-22</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.7640</td>\n",
       "      <td>0.236875</td>\n",
       "      <td>0.118734</td>\n",
       "      <td>0.083988</td>\n",
       "      <td>0.560404</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>0.588875</td>\n",
       "      <td>0.000145</td>\n",
       "      <td>1</td>\n",
       "      <td>2183</td>\n",
       "      <td>3273</td>\n",
       "      <td>2957</td>\n",
       "      <td>4719</td>\n",
       "      <td>316</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1105453</th>\n",
       "      <td>alrx1</td>\n",
       "      <td>2014-05-26</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.355</td>\n",
       "      <td>0.9214</td>\n",
       "      <td>0.009733</td>\n",
       "      <td>0.969973</td>\n",
       "      <td>0.012901</td>\n",
       "      <td>0.007393</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000496</td>\n",
       "      <td>0.019199</td>\n",
       "      <td>0.000480</td>\n",
       "      <td>1</td>\n",
       "      <td>2183</td>\n",
       "      <td>3277</td>\n",
       "      <td>2957</td>\n",
       "      <td>4719</td>\n",
       "      <td>320</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1084060</th>\n",
       "      <td>alrx1</td>\n",
       "      <td>2014-06-01</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.860</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.9100</td>\n",
       "      <td>0.070987</td>\n",
       "      <td>0.050163</td>\n",
       "      <td>0.021271</td>\n",
       "      <td>0.857578</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>0.489165</td>\n",
       "      <td>0.000210</td>\n",
       "      <td>1</td>\n",
       "      <td>2183</td>\n",
       "      <td>3283</td>\n",
       "      <td>2957</td>\n",
       "      <td>4719</td>\n",
       "      <td>326</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>955563</th>\n",
       "      <td>alrx1</td>\n",
       "      <td>2014-06-02</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0.692</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.8225</td>\n",
       "      <td>0.094395</td>\n",
       "      <td>0.295655</td>\n",
       "      <td>0.049789</td>\n",
       "      <td>0.560161</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000474</td>\n",
       "      <td>0.165989</td>\n",
       "      <td>0.000459</td>\n",
       "      <td>1</td>\n",
       "      <td>2183</td>\n",
       "      <td>3284</td>\n",
       "      <td>2957</td>\n",
       "      <td>4719</td>\n",
       "      <td>327</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>912777</th>\n",
       "      <td>alrx1</td>\n",
       "      <td>2014-06-03</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.9945</td>\n",
       "      <td>0.039843</td>\n",
       "      <td>0.804766</td>\n",
       "      <td>0.088519</td>\n",
       "      <td>0.066873</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.138237</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>1</td>\n",
       "      <td>2183</td>\n",
       "      <td>3285</td>\n",
       "      <td>2957</td>\n",
       "      <td>4719</td>\n",
       "      <td>328</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1169717</th>\n",
       "      <td>alrx1</td>\n",
       "      <td>2014-06-04</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.5994</td>\n",
       "      <td>0.060053</td>\n",
       "      <td>0.485211</td>\n",
       "      <td>0.134606</td>\n",
       "      <td>0.320131</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.000390</td>\n",
       "      <td>1</td>\n",
       "      <td>2183</td>\n",
       "      <td>3286</td>\n",
       "      <td>2957</td>\n",
       "      <td>4719</td>\n",
       "      <td>329</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998327</th>\n",
       "      <td>alrx1</td>\n",
       "      <td>2014-06-05</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.735</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.3400</td>\n",
       "      <td>0.026995</td>\n",
       "      <td>0.078730</td>\n",
       "      <td>0.011559</td>\n",
       "      <td>0.882717</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000730</td>\n",
       "      <td>0.061852</td>\n",
       "      <td>0.000707</td>\n",
       "      <td>1</td>\n",
       "      <td>2183</td>\n",
       "      <td>3287</td>\n",
       "      <td>2957</td>\n",
       "      <td>4719</td>\n",
       "      <td>330</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600767</th>\n",
       "      <td>alrx1</td>\n",
       "      <td>2014-06-09</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.705</td>\n",
       "      <td>0.249</td>\n",
       "      <td>0.9671</td>\n",
       "      <td>0.009944</td>\n",
       "      <td>0.948147</td>\n",
       "      <td>0.030443</td>\n",
       "      <td>0.011465</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000252</td>\n",
       "      <td>0.014482</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>1</td>\n",
       "      <td>2183</td>\n",
       "      <td>3291</td>\n",
       "      <td>2957</td>\n",
       "      <td>4719</td>\n",
       "      <td>334</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2080351</th>\n",
       "      <td>alrx1</td>\n",
       "      <td>2014-06-11</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.113</td>\n",
       "      <td>0.6998</td>\n",
       "      <td>0.026226</td>\n",
       "      <td>0.759971</td>\n",
       "      <td>0.152358</td>\n",
       "      <td>0.061445</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000310</td>\n",
       "      <td>0.538635</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1</td>\n",
       "      <td>2183</td>\n",
       "      <td>3293</td>\n",
       "      <td>2957</td>\n",
       "      <td>4719</td>\n",
       "      <td>336</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1437439</th>\n",
       "      <td>alrx1</td>\n",
       "      <td>2014-06-21</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.719</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.8328</td>\n",
       "      <td>0.007033</td>\n",
       "      <td>0.958676</td>\n",
       "      <td>0.015997</td>\n",
       "      <td>0.018294</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000493</td>\n",
       "      <td>0.023032</td>\n",
       "      <td>0.000477</td>\n",
       "      <td>1</td>\n",
       "      <td>2183</td>\n",
       "      <td>3303</td>\n",
       "      <td>2957</td>\n",
       "      <td>4719</td>\n",
       "      <td>346</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>923498</th>\n",
       "      <td>alrx1</td>\n",
       "      <td>2014-07-03</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.826</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.9958</td>\n",
       "      <td>0.538313</td>\n",
       "      <td>0.104306</td>\n",
       "      <td>0.040295</td>\n",
       "      <td>0.317087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.698486</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>1</td>\n",
       "      <td>2183</td>\n",
       "      <td>3315</td>\n",
       "      <td>2957</td>\n",
       "      <td>4719</td>\n",
       "      <td>358</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1448241</th>\n",
       "      <td>alrx1</td>\n",
       "      <td>2014-07-26</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.741</td>\n",
       "      <td>0.177</td>\n",
       "      <td>0.9544</td>\n",
       "      <td>0.093082</td>\n",
       "      <td>0.023196</td>\n",
       "      <td>0.007734</td>\n",
       "      <td>0.875988</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>0.006149</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>1</td>\n",
       "      <td>2183</td>\n",
       "      <td>3338</td>\n",
       "      <td>2957</td>\n",
       "      <td>4719</td>\n",
       "      <td>381</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193399</th>\n",
       "      <td>alrx1</td>\n",
       "      <td>2014-07-27</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.783</td>\n",
       "      <td>0.217</td>\n",
       "      <td>0.9432</td>\n",
       "      <td>0.009001</td>\n",
       "      <td>0.970185</td>\n",
       "      <td>0.011420</td>\n",
       "      <td>0.009393</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000302</td>\n",
       "      <td>0.012618</td>\n",
       "      <td>0.000292</td>\n",
       "      <td>1</td>\n",
       "      <td>2183</td>\n",
       "      <td>3339</td>\n",
       "      <td>2957</td>\n",
       "      <td>4719</td>\n",
       "      <td>382</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1298130</th>\n",
       "      <td>alrx1</td>\n",
       "      <td>2014-08-19</td>\n",
       "      <td>0.183</td>\n",
       "      <td>0.737</td>\n",
       "      <td>0.080</td>\n",
       "      <td>-0.5808</td>\n",
       "      <td>0.094338</td>\n",
       "      <td>0.207819</td>\n",
       "      <td>0.055056</td>\n",
       "      <td>0.642787</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000575</td>\n",
       "      <td>0.025171</td>\n",
       "      <td>0.000556</td>\n",
       "      <td>1</td>\n",
       "      <td>2183</td>\n",
       "      <td>3362</td>\n",
       "      <td>2957</td>\n",
       "      <td>4719</td>\n",
       "      <td>405</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354710</th>\n",
       "      <td>alrx1</td>\n",
       "      <td>2014-08-21</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.774</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.7756</td>\n",
       "      <td>0.029107</td>\n",
       "      <td>0.756633</td>\n",
       "      <td>0.042330</td>\n",
       "      <td>0.171930</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000210</td>\n",
       "      <td>0.008757</td>\n",
       "      <td>0.000203</td>\n",
       "      <td>1</td>\n",
       "      <td>2183</td>\n",
       "      <td>3364</td>\n",
       "      <td>2957</td>\n",
       "      <td>4719</td>\n",
       "      <td>407</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1587131</th>\n",
       "      <td>alrx1</td>\n",
       "      <td>2014-09-16</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.884</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.8376</td>\n",
       "      <td>0.288401</td>\n",
       "      <td>0.284511</td>\n",
       "      <td>0.320402</td>\n",
       "      <td>0.106686</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.009008</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>1</td>\n",
       "      <td>2183</td>\n",
       "      <td>3390</td>\n",
       "      <td>2957</td>\n",
       "      <td>4719</td>\n",
       "      <td>433</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2101832</th>\n",
       "      <td>alrx1</td>\n",
       "      <td>2014-09-19</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.894</td>\n",
       "      <td>0.058</td>\n",
       "      <td>-0.3729</td>\n",
       "      <td>0.457554</td>\n",
       "      <td>0.026050</td>\n",
       "      <td>0.024710</td>\n",
       "      <td>0.491686</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000213</td>\n",
       "      <td>0.009306</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>1</td>\n",
       "      <td>2183</td>\n",
       "      <td>3393</td>\n",
       "      <td>2957</td>\n",
       "      <td>4719</td>\n",
       "      <td>436</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1748315</th>\n",
       "      <td>alrx1</td>\n",
       "      <td>2014-11-08</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.6686</td>\n",
       "      <td>0.077752</td>\n",
       "      <td>0.434014</td>\n",
       "      <td>0.197102</td>\n",
       "      <td>0.291133</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.009316</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>1</td>\n",
       "      <td>2183</td>\n",
       "      <td>3443</td>\n",
       "      <td>2957</td>\n",
       "      <td>4719</td>\n",
       "      <td>486</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1641012</th>\n",
       "      <td>alrx1</td>\n",
       "      <td>2014-12-18</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.734</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.8002</td>\n",
       "      <td>0.101250</td>\n",
       "      <td>0.411878</td>\n",
       "      <td>0.113682</td>\n",
       "      <td>0.373190</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000680</td>\n",
       "      <td>0.270678</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>1</td>\n",
       "      <td>2183</td>\n",
       "      <td>3483</td>\n",
       "      <td>2957</td>\n",
       "      <td>4719</td>\n",
       "      <td>526</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1340805</th>\n",
       "      <td>alrx1</td>\n",
       "      <td>2018-03-12</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.954</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.3182</td>\n",
       "      <td>0.714580</td>\n",
       "      <td>0.012301</td>\n",
       "      <td>0.044649</td>\n",
       "      <td>0.228470</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000574</td>\n",
       "      <td>0.633631</td>\n",
       "      <td>0.000556</td>\n",
       "      <td>1</td>\n",
       "      <td>2183</td>\n",
       "      <td>4663</td>\n",
       "      <td>2957</td>\n",
       "      <td>4719</td>\n",
       "      <td>1706</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1394374</th>\n",
       "      <td>alrx1</td>\n",
       "      <td>2018-05-02</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.931</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.5363</td>\n",
       "      <td>0.058851</td>\n",
       "      <td>0.148005</td>\n",
       "      <td>0.075174</td>\n",
       "      <td>0.717970</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000546</td>\n",
       "      <td>0.026312</td>\n",
       "      <td>0.000528</td>\n",
       "      <td>1</td>\n",
       "      <td>2183</td>\n",
       "      <td>4714</td>\n",
       "      <td>2957</td>\n",
       "      <td>4719</td>\n",
       "      <td>1757</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86007</th>\n",
       "      <td>alrx1</td>\n",
       "      <td>2018-05-07</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.764</td>\n",
       "      <td>0.236</td>\n",
       "      <td>0.7964</td>\n",
       "      <td>0.054423</td>\n",
       "      <td>0.366234</td>\n",
       "      <td>0.349807</td>\n",
       "      <td>0.229535</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000915</td>\n",
       "      <td>0.125508</td>\n",
       "      <td>0.000886</td>\n",
       "      <td>1</td>\n",
       "      <td>2183</td>\n",
       "      <td>4719</td>\n",
       "      <td>2957</td>\n",
       "      <td>4719</td>\n",
       "      <td>1762</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30 rows Ã— 296 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_url         day    neg    neu    pos  compound     anger  \\\n",
       "1180372    alrx1  2014-02-20  0.059  0.814  0.127    0.9707  0.260971   \n",
       "751159     alrx1  2014-03-25  0.000  0.610  0.390    0.9821  0.009462   \n",
       "1159025    alrx1  2014-03-26  0.069  0.567  0.364    0.9730  0.013523   \n",
       "1394373    alrx1  2014-03-27  0.214  0.588  0.198   -0.3267  0.022793   \n",
       "429723     alrx1  2014-04-07  0.000  0.625  0.375    0.9451  0.007536   \n",
       "1919442    alrx1  2014-04-19  0.074  0.763  0.164    0.9495  0.062314   \n",
       "1597890    alrx1  2014-05-02  0.000  0.803  0.197    0.8900  0.015495   \n",
       "1726961    alrx1  2014-05-13  0.000  0.830  0.170    0.8645  0.051312   \n",
       "1126868    alrx1  2014-05-22  0.103  0.786  0.111    0.7640  0.236875   \n",
       "1105453    alrx1  2014-05-26  0.000  0.645  0.355    0.9214  0.009733   \n",
       "1084060    alrx1  2014-06-01  0.020  0.860  0.120    0.9100  0.070987   \n",
       "955563     alrx1  2014-06-02  0.097  0.692  0.211    0.8225  0.094395   \n",
       "912777     alrx1  2014-06-03  0.035  0.775  0.190    0.9945  0.039843   \n",
       "1169717    alrx1  2014-06-04  0.043  0.880  0.077    0.5994  0.060053   \n",
       "998327     alrx1  2014-06-05  0.107  0.735  0.158    0.3400  0.026995   \n",
       "600767     alrx1  2014-06-09  0.046  0.705  0.249    0.9671  0.009944   \n",
       "2080351    alrx1  2014-06-11  0.063  0.825  0.113    0.6998  0.026226   \n",
       "1437439    alrx1  2014-06-21  0.059  0.719  0.222    0.8328  0.007033   \n",
       "923498     alrx1  2014-07-03  0.014  0.826  0.160    0.9958  0.538313   \n",
       "1448241    alrx1  2014-07-26  0.083  0.741  0.177    0.9544  0.093082   \n",
       "193399     alrx1  2014-07-27  0.000  0.783  0.217    0.9432  0.009001   \n",
       "1298130    alrx1  2014-08-19  0.183  0.737  0.080   -0.5808  0.094338   \n",
       "354710     alrx1  2014-08-21  0.076  0.774  0.150    0.7756  0.029107   \n",
       "1587131    alrx1  2014-09-16  0.029  0.884  0.087    0.8376  0.288401   \n",
       "2101832    alrx1  2014-09-19  0.047  0.894  0.058   -0.3729  0.457554   \n",
       "1748315    alrx1  2014-11-08  0.059  0.850  0.091    0.6686  0.077752   \n",
       "1641012    alrx1  2014-12-18  0.050  0.734  0.215    0.8002  0.101250   \n",
       "1340805    alrx1  2018-03-12  0.000  0.954  0.046    0.3182  0.714580   \n",
       "1394374    alrx1  2018-05-02  0.069  0.931  0.000   -0.5363  0.058851   \n",
       "86007      alrx1  2018-05-07  0.000  0.764  0.236    0.7964  0.054423   \n",
       "\n",
       "              joy  optimism   sadness  ...  topic_17  topic_18  topic_19  \\\n",
       "1180372  0.056864  0.072216  0.609949  ...  0.000108  0.545847  0.000105   \n",
       "751159   0.964755  0.014913  0.010870  ...  0.000359  0.015341  0.000348   \n",
       "1159025  0.924859  0.047491  0.014127  ...  0.000474  0.248984  0.000458   \n",
       "1394373  0.035690  0.012705  0.928812  ...  0.000114  0.005351  0.000110   \n",
       "429723   0.964907  0.015495  0.012063  ...  0.000643  0.025142  0.000623   \n",
       "1919442  0.085534  0.061200  0.790952  ...  0.000153  0.006527  0.000148   \n",
       "1597890  0.907554  0.050404  0.026547  ...  0.000351  0.022017  0.000340   \n",
       "1726961  0.769607  0.090021  0.089060  ...  0.000419  0.020138  0.000405   \n",
       "1126868  0.118734  0.083988  0.560404  ...  0.000150  0.588875  0.000145   \n",
       "1105453  0.969973  0.012901  0.007393  ...  0.000496  0.019199  0.000480   \n",
       "1084060  0.050163  0.021271  0.857578  ...  0.000217  0.489165  0.000210   \n",
       "955563   0.295655  0.049789  0.560161  ...  0.000474  0.165989  0.000459   \n",
       "912777   0.804766  0.088519  0.066873  ...  0.000082  0.138237  0.000079   \n",
       "1169717  0.485211  0.134606  0.320131  ...  0.000403  0.600000  0.000390   \n",
       "998327   0.078730  0.011559  0.882717  ...  0.000730  0.061852  0.000707   \n",
       "600767   0.948147  0.030443  0.011465  ...  0.000252  0.014482  0.000244   \n",
       "2080351  0.759971  0.152358  0.061445  ...  0.000310  0.538635  0.000300   \n",
       "1437439  0.958676  0.015997  0.018294  ...  0.000493  0.023032  0.000477   \n",
       "923498   0.104306  0.040295  0.317087  ...  0.000077  0.698486  0.000075   \n",
       "1448241  0.023196  0.007734  0.875988  ...  0.000149  0.006149  0.000144   \n",
       "193399   0.970185  0.011420  0.009393  ...  0.000302  0.012618  0.000292   \n",
       "1298130  0.207819  0.055056  0.642787  ...  0.000575  0.025171  0.000556   \n",
       "354710   0.756633  0.042330  0.171930  ...  0.000210  0.008757  0.000203   \n",
       "1587131  0.284511  0.320402  0.106686  ...  0.000194  0.009008  0.000188   \n",
       "2101832  0.026050  0.024710  0.491686  ...  0.000213  0.009306  0.000206   \n",
       "1748315  0.434014  0.197102  0.291133  ...  0.000181  0.009316  0.000175   \n",
       "1641012  0.411878  0.113682  0.373190  ...  0.000680  0.270678  0.000658   \n",
       "1340805  0.012301  0.044649  0.228470  ...  0.000574  0.633631  0.000556   \n",
       "1394374  0.148005  0.075174  0.717970  ...  0.000546  0.026312  0.000528   \n",
       "86007    0.366234  0.349807  0.229535  ...  0.000915  0.125508  0.000886   \n",
       "\n",
       "         sn_user  user_id  time_period  first_period  last_period  \\\n",
       "1180372        1     2183         3182          2957         4719   \n",
       "751159         1     2183         3215          2957         4719   \n",
       "1159025        1     2183         3216          2957         4719   \n",
       "1394373        1     2183         3217          2957         4719   \n",
       "429723         1     2183         3228          2957         4719   \n",
       "1919442        1     2183         3240          2957         4719   \n",
       "1597890        1     2183         3253          2957         4719   \n",
       "1726961        1     2183         3264          2957         4719   \n",
       "1126868        1     2183         3273          2957         4719   \n",
       "1105453        1     2183         3277          2957         4719   \n",
       "1084060        1     2183         3283          2957         4719   \n",
       "955563         1     2183         3284          2957         4719   \n",
       "912777         1     2183         3285          2957         4719   \n",
       "1169717        1     2183         3286          2957         4719   \n",
       "998327         1     2183         3287          2957         4719   \n",
       "600767         1     2183         3291          2957         4719   \n",
       "2080351        1     2183         3293          2957         4719   \n",
       "1437439        1     2183         3303          2957         4719   \n",
       "923498         1     2183         3315          2957         4719   \n",
       "1448241        1     2183         3338          2957         4719   \n",
       "193399         1     2183         3339          2957         4719   \n",
       "1298130        1     2183         3362          2957         4719   \n",
       "354710         1     2183         3364          2957         4719   \n",
       "1587131        1     2183         3390          2957         4719   \n",
       "2101832        1     2183         3393          2957         4719   \n",
       "1748315        1     2183         3443          2957         4719   \n",
       "1641012        1     2183         3483          2957         4719   \n",
       "1340805        1     2183         4663          2957         4719   \n",
       "1394374        1     2183         4714          2957         4719   \n",
       "86007          1     2183         4719          2957         4719   \n",
       "\n",
       "         time_since_first_period  is_last_period  \n",
       "1180372                      225               0  \n",
       "751159                       258               0  \n",
       "1159025                      259               0  \n",
       "1394373                      260               0  \n",
       "429723                       271               0  \n",
       "1919442                      283               0  \n",
       "1597890                      296               0  \n",
       "1726961                      307               0  \n",
       "1126868                      316               0  \n",
       "1105453                      320               0  \n",
       "1084060                      326               0  \n",
       "955563                       327               0  \n",
       "912777                       328               0  \n",
       "1169717                      329               0  \n",
       "998327                       330               0  \n",
       "600767                       334               0  \n",
       "2080351                      336               0  \n",
       "1437439                      346               0  \n",
       "923498                       358               0  \n",
       "1448241                      381               0  \n",
       "193399                       382               0  \n",
       "1298130                      405               0  \n",
       "354710                       407               0  \n",
       "1587131                      433               0  \n",
       "2101832                      436               0  \n",
       "1748315                      486               0  \n",
       "1641012                      526               0  \n",
       "1340805                     1706               0  \n",
       "1394374                     1757               0  \n",
       "86007                       1762               1  \n",
       "\n",
       "[30 rows x 296 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['user_url']=='alrx1'].sort_values('day').tail(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(path_joined_pkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_sql = '''\n",
    "    SELECT\n",
    "        p.id AS post_id,\n",
    "        p.user_url,\n",
    "        f.id AS forum_id\n",
    "    FROM posts AS p\n",
    "    LEFT JOIN threads AS t\n",
    "    ON t.id=p.thread_id\n",
    "    LEFT JOIN subforums AS s\n",
    "    ON s.id=t.subforum_id\n",
    "    LEFT JOIN forums AS f\n",
    "    ON f.id=s.forum_id\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = create_connection(path_db)\n",
    "sn_users = pd.read_sql_query(posts_sql, conn)\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "sn_users = sn_users.loc[sn_users['forum_id']==24]\n",
    "sn_users = sn_users.drop_duplicates('user_url')[['user_url']]\n",
    "sn_users = sn_users.loc[sn_users['user_url']!=\"Anonymous\"]\n",
    "sn_users.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sn_user'] = 0\n",
    "df.loc[df['user_url'].isin(sn_users['user_url']), 'sn_user'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['user_id'] = df.groupby('user_url').ngroup()\n",
    "df['time_period'] = df.sort_values(['day']).groupby(['day']).ngroup()\n",
    "df['first_period'] = df.groupby(['user_url'])['time_period'].transform('min')\n",
    "df['last_period'] = df.groupby(['user_url'])['time_period'].transform('max')\n",
    "df['time_since_first_period'] = df['time_period'] - df['first_period']\n",
    "df['is_last_period'] = 0\n",
    "df.loc[df['time_period']==df['last_period'], 'is_last_period'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(path_joined_pkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cols = list(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_sn_post_sql = '''\n",
    "WITH added_row_number AS (\n",
    "    SELECT\n",
    "        p.id AS post_id,\n",
    "        p.user_url,\n",
    "        p.date_created,\n",
    "        ROW_NUMBER() OVER(PARTITION BY p.user_url ORDER BY p.date_created ASC) AS row_number\n",
    "    FROM posts AS p\n",
    "    LEFT JOIN threads AS t\n",
    "    ON t.id=p.thread_id\n",
    "    LEFT JOIN subforums AS s\n",
    "    ON s.id=t.subforum_id\n",
    "    WHERE s.forum_id=24\n",
    ")\n",
    "SELECT\n",
    "  *\n",
    "FROM added_row_number\n",
    "WHERE row_number = 1;\n",
    "'''\n",
    "conn = create_connection(path_db)\n",
    "first_sn_post = pd.read_sql_query(first_sn_post_sql, conn)\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_sn_post['day'] = pd.to_datetime(first_sn_post['date_created']).dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_sn_post = first_sn_post.rename(columns={'day':'first_sn_day'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_sn_post = first_sn_post[['user_url', 'first_sn_day']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_sn_post.to_csv(path_clean_data / \"first_sn_day.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>thread_id</th>\n",
       "      <th>post_count</th>\n",
       "      <th>post_id</th>\n",
       "      <th>user_url</th>\n",
       "      <th>date_created</th>\n",
       "      <th>date_recorded</th>\n",
       "      <th>body</th>\n",
       "      <th>version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15295652</td>\n",
       "      <td>1237966</td>\n",
       "      <td>8</td>\n",
       "      <td>19717478</td>\n",
       "      <td>aarthi-s-3</td>\n",
       "      <td>2020-01-27 08:28PM</td>\n",
       "      <td>2021-03-07 02:35:12</td>\n",
       "      <td>Hi i am desperate for some good advice to get ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  thread_id  post_count   post_id    user_url        date_created  \\\n",
       "0  15295652    1237966           8  19717478  aarthi-s-3  2020-01-27 08:28PM   \n",
       "\n",
       "         date_recorded                                               body  \\\n",
       "0  2021-03-07 02:35:12  Hi i am desperate for some good advice to get ...   \n",
       "\n",
       "   version  \n",
       "0        1  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql = \"\"\"\n",
    "SELECT *\n",
    "FROM posts\n",
    "WHERE user_url = 'aarthi-s-3'\n",
    "\"\"\"\n",
    "conn = create_connection(path_db)\n",
    "test = pd.read_sql_query(sql, conn)\n",
    "conn.close()\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Panel Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['user_url',\n",
       " 'day',\n",
       " 'anger',\n",
       " 'joy',\n",
       " 'optimism',\n",
       " 'sadness',\n",
       " 'sn_user',\n",
       " 'user_id',\n",
       " 'time_period',\n",
       " 'first_period',\n",
       " 'last_period',\n",
       " 'time_since_first_period',\n",
       " 'is_last_period']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_panel = [all_cols[i] for i in [0, 1, 6, 7, 8, 9, 289, 290, 291, 292, 293, 294, 295]]\n",
    "cols_panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_panel = df[cols_panel].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_panel['year'] = pd.DatetimeIndex(df_panel['day']).year\n",
    "df_panel['month'] = pd.DatetimeIndex(df_panel['day']).month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_url</th>\n",
       "      <th>day</th>\n",
       "      <th>anger</th>\n",
       "      <th>joy</th>\n",
       "      <th>optimism</th>\n",
       "      <th>sadness</th>\n",
       "      <th>sn_user</th>\n",
       "      <th>user_id</th>\n",
       "      <th>time_period</th>\n",
       "      <th>first_period</th>\n",
       "      <th>last_period</th>\n",
       "      <th>time_since_first_period</th>\n",
       "      <th>is_last_period</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>546615</th>\n",
       "      <td>0407nc</td>\n",
       "      <td>2017-02-25</td>\n",
       "      <td>0.027597</td>\n",
       "      <td>0.010135</td>\n",
       "      <td>0.014064</td>\n",
       "      <td>0.948204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4283</td>\n",
       "      <td>4283</td>\n",
       "      <td>4364</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365103</th>\n",
       "      <td>0407nc</td>\n",
       "      <td>2017-02-28</td>\n",
       "      <td>0.031126</td>\n",
       "      <td>0.009913</td>\n",
       "      <td>0.006925</td>\n",
       "      <td>0.952036</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4286</td>\n",
       "      <td>4283</td>\n",
       "      <td>4364</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1554764</th>\n",
       "      <td>0407nc</td>\n",
       "      <td>2017-03-01</td>\n",
       "      <td>0.010955</td>\n",
       "      <td>0.012001</td>\n",
       "      <td>0.006985</td>\n",
       "      <td>0.970060</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4287</td>\n",
       "      <td>4283</td>\n",
       "      <td>4364</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976701</th>\n",
       "      <td>0407nc</td>\n",
       "      <td>2017-03-02</td>\n",
       "      <td>0.023654</td>\n",
       "      <td>0.808639</td>\n",
       "      <td>0.116215</td>\n",
       "      <td>0.051492</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4288</td>\n",
       "      <td>4283</td>\n",
       "      <td>4364</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1812262</th>\n",
       "      <td>0407nc</td>\n",
       "      <td>2017-03-14</td>\n",
       "      <td>0.017647</td>\n",
       "      <td>0.397049</td>\n",
       "      <td>0.031483</td>\n",
       "      <td>0.553821</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4300</td>\n",
       "      <td>4283</td>\n",
       "      <td>4364</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_url         day     anger       joy  optimism   sadness  sn_user  \\\n",
       "546615    0407nc  2017-02-25  0.027597  0.010135  0.014064  0.948204        0   \n",
       "365103    0407nc  2017-02-28  0.031126  0.009913  0.006925  0.952036        0   \n",
       "1554764   0407nc  2017-03-01  0.010955  0.012001  0.006985  0.970060        0   \n",
       "976701    0407nc  2017-03-02  0.023654  0.808639  0.116215  0.051492        0   \n",
       "1812262   0407nc  2017-03-14  0.017647  0.397049  0.031483  0.553821        0   \n",
       "\n",
       "         user_id  time_period  first_period  last_period  \\\n",
       "546615         0         4283          4283         4364   \n",
       "365103         0         4286          4283         4364   \n",
       "1554764        0         4287          4283         4364   \n",
       "976701         0         4288          4283         4364   \n",
       "1812262        0         4300          4283         4364   \n",
       "\n",
       "         time_since_first_period  is_last_period  year  month  \n",
       "546615                         0               0  2017      2  \n",
       "365103                         3               0  2017      2  \n",
       "1554764                        4               0  2017      3  \n",
       "976701                         5               0  2017      3  \n",
       "1812262                       17               0  2017      3  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_panel.sort_values(['user_url', 'day']).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_panel['day'] = df_panel['day'].apply(lambda x: x.strftime('%Y-%m-%d'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_panel.to_stata(path_clean_data / \"daily_panel.dta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cox Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(path_clean_data / \"daily_all.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cox = df[cols_cox].copy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
